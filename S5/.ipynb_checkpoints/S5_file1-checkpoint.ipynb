{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Creating Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9895936/9912422 [00:47<00:00, 196202.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      "32768it [00:01, 31473.03it/s]                           \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:00<00:31, 51819.21it/s]\u001b[A\n",
      "  2%|▏         | 40960/1648877 [00:01<00:27, 58468.08it/s]\u001b[A\n",
      "  5%|▌         | 90112/1648877 [00:01<00:21, 72142.27it/s]\u001b[A\n",
      "  8%|▊         | 139264/1648877 [00:01<00:17, 86407.96it/s]\u001b[A\n",
      " 11%|█▏        | 188416/1648877 [00:02<00:14, 100230.37it/s]\u001b[A\n",
      " 15%|█▍        | 245760/1648877 [00:02<00:12, 116317.51it/s]\u001b[A\n",
      " 18%|█▊        | 303104/1648877 [00:02<00:10, 130623.89it/s]\u001b[A\n",
      " 22%|██▏       | 360448/1648877 [00:03<00:08, 143871.94it/s]\u001b[A\n",
      " 26%|██▌       | 425984/1648877 [00:03<00:07, 159924.13it/s]\u001b[A\n",
      " 30%|██▉       | 491520/1648877 [00:03<00:06, 186170.35it/s]\u001b[A\n",
      " 34%|███▍      | 557056/1648877 [00:03<00:05, 195976.67it/s]\u001b[A\n",
      " 38%|███▊      | 630784/1648877 [00:04<00:05, 175880.44it/s]\u001b[A\n",
      " 43%|████▎     | 704512/1648877 [00:04<00:04, 208734.74it/s]\u001b[A\n",
      " 46%|████▌     | 761856/1648877 [00:04<00:04, 202058.07it/s]\u001b[A\n",
      " 50%|████▉     | 819200/1648877 [00:05<00:03, 219115.86it/s]\u001b[A\n",
      " 54%|█████▎    | 884736/1648877 [00:05<00:03, 238037.48it/s]\u001b[A\n",
      " 58%|█████▊    | 950272/1648877 [00:05<00:02, 234680.59it/s]\u001b[A\n",
      " 62%|██████▏   | 1015808/1648877 [00:05<00:02, 227727.94it/s]\u001b[A\n",
      " 66%|██████▌   | 1081344/1648877 [00:06<00:02, 200283.32it/s]\u001b[A\n",
      " 72%|███████▏  | 1187840/1648877 [00:06<00:01, 230757.40it/s]\u001b[A\n",
      " 75%|███████▌  | 1236992/1648877 [00:06<00:02, 203662.22it/s]\u001b[A\n",
      " 78%|███████▊  | 1294336/1648877 [00:07<00:01, 198425.65it/s]\u001b[A\n",
      " 82%|████████▏ | 1351680/1648877 [00:07<00:01, 194551.44it/s]\u001b[A\n",
      " 85%|████████▌ | 1409024/1648877 [00:07<00:01, 192167.47it/s]\u001b[A\n",
      " 89%|████████▉ | 1474560/1648877 [00:08<00:00, 198067.04it/s]\u001b[A\n",
      " 93%|█████████▎| 1531904/1648877 [00:08<00:00, 215510.37it/s]\u001b[A\n",
      " 97%|█████████▋| 1597440/1648877 [00:08<00:00, 216314.36it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8192it [00:00, 15495.97it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST('./data',\n",
    "                              train=True,\n",
    "                              transform=train_transforms,\n",
    "                              download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST('./data',\n",
    "                              train=False,\n",
    "                              transform=test_transforms,\n",
    "                              download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, **dataloader_args)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, **dataloader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy shape  (60000, 28, 28)\n",
      "Tensor size  torch.Size([60000, 28, 28])\n",
      "min  tensor(-0.4242)\n",
      "max  tensor(2.8215)\n",
      "mean  tensor(0.0006)\n",
      "std  tensor(1.0000)\n",
      "var  tensor(1.0001)\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_dataset.data\n",
    "train_data = train_dataset.transform(train_data.numpy())\n",
    "\n",
    "print('Numpy shape ', train_dataset.data.cpu().numpy().shape)\n",
    "print('Tensor size ', train_dataset.data.size())\n",
    "print('min ', torch.min(train_data))\n",
    "print('max ', torch.max(train_data))\n",
    "print('mean ', torch.mean(train_data))\n",
    "print('std ', torch.std(train_data))\n",
    "print('var ', torch.var(train_data))\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Input Block\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU()\n",
    "        ) # output_size = 26\n",
    "\n",
    "        # CONVOLUTION BLOCK 1\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU()\n",
    "        ) # output_size = 24\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU()\n",
    "        ) # output_size = 22\n",
    "\n",
    "        # TRANSITION BLOCK 1\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 11\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=32, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU()\n",
    "        ) # output_size = 11\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU()\n",
    "        ) # output_size = 9\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU()\n",
    "        ) # output_size = 7\n",
    "\n",
    "        # OUTPUT BLOCK\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU()\n",
    "        ) # output_size = 7\n",
    "        self.convblock8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(7, 7), padding=0, bias=False),\n",
    "            # nn.ReLU() NEVER!\n",
    "        ) # output_size = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.convblock8(x)\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             288\n",
      "              ReLU-2           [-1, 32, 26, 26]               0\n",
      "            Conv2d-3           [-1, 64, 24, 24]          18,432\n",
      "              ReLU-4           [-1, 64, 24, 24]               0\n",
      "            Conv2d-5          [-1, 128, 22, 22]          73,728\n",
      "              ReLU-6          [-1, 128, 22, 22]               0\n",
      "         MaxPool2d-7          [-1, 128, 11, 11]               0\n",
      "            Conv2d-8           [-1, 32, 11, 11]           4,096\n",
      "              ReLU-9           [-1, 32, 11, 11]               0\n",
      "           Conv2d-10             [-1, 64, 9, 9]          18,432\n",
      "             ReLU-11             [-1, 64, 9, 9]               0\n",
      "           Conv2d-12            [-1, 128, 7, 7]          73,728\n",
      "             ReLU-13            [-1, 128, 7, 7]               0\n",
      "           Conv2d-14             [-1, 10, 7, 7]           1,280\n",
      "             ReLU-15             [-1, 10, 7, 7]               0\n",
      "           Conv2d-16             [-1, 10, 1, 1]           4,900\n",
      "================================================================\n",
      "Total params: 194,884\n",
      "Trainable params: 194,884\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.20\n",
      "Params size (MB): 0.74\n",
      "Estimated Total Size (MB): 2.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model(data)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "    \n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025338649749756 Batch_id=0 Accuracy=9.38:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025338649749756 Batch_id=0 Accuracy=9.38:   0%|          | 1/938 [00:00<02:38,  5.90it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss=2.3027563095092773 Batch_id=1 Accuracy=7.81:   0%|          | 1/938 [00:00<02:38,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3027563095092773 Batch_id=1 Accuracy=7.81:   0%|          | 2/938 [00:00<02:31,  6.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302349328994751 Batch_id=2 Accuracy=8.33:   0%|          | 2/938 [00:00<02:31,  6.16it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302349328994751 Batch_id=2 Accuracy=8.33:   0%|          | 3/938 [00:00<02:25,  6.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.30299711227417 Batch_id=3 Accuracy=7.42:   0%|          | 3/938 [00:00<02:25,  6.41it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.30299711227417 Batch_id=3 Accuracy=7.42:   0%|          | 4/938 [00:00<02:21,  6.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3027634620666504 Batch_id=4 Accuracy=7.50:   0%|          | 4/938 [00:00<02:21,  6.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3027634620666504 Batch_id=4 Accuracy=7.50:   1%|          | 5/938 [00:00<02:22,  6.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023908138275146 Batch_id=5 Accuracy=7.55:   1%|          | 5/938 [00:00<02:22,  6.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023908138275146 Batch_id=5 Accuracy=7.55:   1%|          | 6/938 [00:00<02:16,  6.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025083541870117 Batch_id=6 Accuracy=8.93:   1%|          | 6/938 [00:01<02:16,  6.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025083541870117 Batch_id=6 Accuracy=8.93:   1%|          | 7/938 [00:01<02:25,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3024442195892334 Batch_id=7 Accuracy=9.18:   1%|          | 7/938 [00:01<02:25,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3024442195892334 Batch_id=7 Accuracy=9.18:   1%|          | 8/938 [00:01<02:20,  6.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3024163246154785 Batch_id=8 Accuracy=9.55:   1%|          | 8/938 [00:01<02:20,  6.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3024163246154785 Batch_id=8 Accuracy=9.55:   1%|          | 9/938 [00:01<02:20,  6.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3026676177978516 Batch_id=9 Accuracy=9.38:   1%|          | 9/938 [00:01<02:20,  6.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3026676177978516 Batch_id=9 Accuracy=9.38:   1%|          | 10/938 [00:01<02:28,  6.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302635431289673 Batch_id=10 Accuracy=9.38:   1%|          | 10/938 [00:01<02:28,  6.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302635431289673 Batch_id=10 Accuracy=9.38:   1%|          | 11/938 [00:01<02:29,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302637815475464 Batch_id=11 Accuracy=9.90:   1%|          | 11/938 [00:01<02:29,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302637815475464 Batch_id=11 Accuracy=9.90:   1%|▏         | 12/938 [00:01<02:27,  6.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3022379875183105 Batch_id=12 Accuracy=9.62:   1%|▏         | 12/938 [00:02<02:27,  6.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3022379875183105 Batch_id=12 Accuracy=9.62:   1%|▏         | 13/938 [00:02<02:28,  6.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3026108741760254 Batch_id=13 Accuracy=9.60:   1%|▏         | 13/938 [00:02<02:28,  6.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3026108741760254 Batch_id=13 Accuracy=9.60:   1%|▏         | 14/938 [00:02<02:27,  6.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302647352218628 Batch_id=14 Accuracy=9.38:   1%|▏         | 14/938 [00:02<02:27,  6.25it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302647352218628 Batch_id=14 Accuracy=9.38:   2%|▏         | 15/938 [00:02<02:44,  5.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302412986755371 Batch_id=15 Accuracy=9.57:   2%|▏         | 15/938 [00:02<02:44,  5.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302412986755371 Batch_id=15 Accuracy=9.57:   2%|▏         | 16/938 [00:02<02:42,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302354574203491 Batch_id=16 Accuracy=9.93:   2%|▏         | 16/938 [00:02<02:42,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302354574203491 Batch_id=16 Accuracy=9.93:   2%|▏         | 17/938 [00:02<02:36,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025622367858887 Batch_id=17 Accuracy=9.90:   2%|▏         | 17/938 [00:02<02:36,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025622367858887 Batch_id=17 Accuracy=9.90:   2%|▏         | 18/938 [00:02<02:39,  5.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302384853363037 Batch_id=18 Accuracy=10.36:   2%|▏         | 18/938 [00:03<02:39,  5.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302384853363037 Batch_id=18 Accuracy=10.36:   2%|▏         | 19/938 [00:03<02:32,  6.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023884296417236 Batch_id=19 Accuracy=10.16:   2%|▏         | 19/938 [00:03<02:32,  6.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023884296417236 Batch_id=19 Accuracy=10.16:   2%|▏         | 20/938 [00:03<02:29,  6.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025732040405273 Batch_id=20 Accuracy=10.04:   2%|▏         | 20/938 [00:03<02:29,  6.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025732040405273 Batch_id=20 Accuracy=10.04:   2%|▏         | 21/938 [00:03<02:34,  5.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.30273699760437 Batch_id=21 Accuracy=10.09:   2%|▏         | 21/938 [00:03<02:34,  5.93it/s]  \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.30273699760437 Batch_id=21 Accuracy=10.09:   2%|▏         | 22/938 [00:03<02:33,  5.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3028457164764404 Batch_id=22 Accuracy=10.12:   2%|▏         | 22/938 [00:03<02:33,  5.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3028457164764404 Batch_id=22 Accuracy=10.12:   2%|▏         | 23/938 [00:03<02:35,  5.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302528142929077 Batch_id=23 Accuracy=10.03:   2%|▏         | 23/938 [00:04<02:35,  5.88it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302528142929077 Batch_id=23 Accuracy=10.03:   3%|▎         | 24/938 [00:04<03:07,  4.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302460193634033 Batch_id=24 Accuracy=10.12:   3%|▎         | 24/938 [00:04<03:07,  4.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302460193634033 Batch_id=24 Accuracy=10.12:   3%|▎         | 25/938 [00:04<03:07,  4.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023884296417236 Batch_id=25 Accuracy=10.04:   3%|▎         | 25/938 [00:04<03:07,  4.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023884296417236 Batch_id=25 Accuracy=10.04:   3%|▎         | 26/938 [00:04<03:09,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023886680603027 Batch_id=26 Accuracy=10.07:   3%|▎         | 26/938 [00:04<03:09,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023886680603027 Batch_id=26 Accuracy=10.07:   3%|▎         | 27/938 [00:04<03:00,  5.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3021531105041504 Batch_id=27 Accuracy=10.27:   3%|▎         | 27/938 [00:04<03:00,  5.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3021531105041504 Batch_id=27 Accuracy=10.27:   3%|▎         | 28/938 [00:04<02:47,  5.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3020920753479004 Batch_id=28 Accuracy=10.29:   3%|▎         | 28/938 [00:04<02:47,  5.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3020920753479004 Batch_id=28 Accuracy=10.29:   3%|▎         | 29/938 [00:04<02:39,  5.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302335739135742 Batch_id=29 Accuracy=10.16:   3%|▎         | 29/938 [00:05<02:39,  5.69it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302335739135742 Batch_id=29 Accuracy=10.16:   3%|▎         | 30/938 [00:05<02:35,  5.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3024239540100098 Batch_id=30 Accuracy=10.03:   3%|▎         | 30/938 [00:05<02:35,  5.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3024239540100098 Batch_id=30 Accuracy=10.03:   3%|▎         | 31/938 [00:05<02:29,  6.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.30208420753479 Batch_id=31 Accuracy=10.30:   3%|▎         | 31/938 [00:05<02:29,  6.07it/s]  \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.30208420753479 Batch_id=31 Accuracy=10.30:   3%|▎         | 32/938 [00:05<02:21,  6.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023507595062256 Batch_id=32 Accuracy=10.37:   3%|▎         | 32/938 [00:05<02:21,  6.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023507595062256 Batch_id=32 Accuracy=10.37:   4%|▎         | 33/938 [00:05<02:18,  6.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302647352218628 Batch_id=33 Accuracy=10.25:   4%|▎         | 33/938 [00:05<02:18,  6.53it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302647352218628 Batch_id=33 Accuracy=10.25:   4%|▎         | 34/938 [00:05<02:27,  6.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025848865509033 Batch_id=34 Accuracy=10.27:   4%|▎         | 34/938 [00:05<02:27,  6.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3025848865509033 Batch_id=34 Accuracy=10.27:   4%|▎         | 35/938 [00:05<02:23,  6.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301819324493408 Batch_id=35 Accuracy=10.63:   4%|▎         | 35/938 [00:06<02:23,  6.30it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301819324493408 Batch_id=35 Accuracy=10.63:   4%|▍         | 36/938 [00:06<02:23,  6.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3018836975097656 Batch_id=36 Accuracy=10.90:   4%|▍         | 36/938 [00:06<02:23,  6.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3018836975097656 Batch_id=36 Accuracy=10.90:   4%|▍         | 37/938 [00:06<02:19,  6.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023297786712646 Batch_id=37 Accuracy=11.06:   4%|▍         | 37/938 [00:06<02:19,  6.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023297786712646 Batch_id=37 Accuracy=11.06:   4%|▍         | 38/938 [00:06<02:20,  6.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023993968963623 Batch_id=38 Accuracy=11.02:   4%|▍         | 38/938 [00:06<02:20,  6.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3023993968963623 Batch_id=38 Accuracy=11.02:   4%|▍         | 39/938 [00:06<02:22,  6.29it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=2.3016703128814697 Batch_id=39 Accuracy=11.17:   4%|▍         | 39/938 [00:06<02:22,  6.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3016703128814697 Batch_id=39 Accuracy=11.17:   4%|▍         | 40/938 [00:06<02:25,  6.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3021249771118164 Batch_id=40 Accuracy=11.32:   4%|▍         | 40/938 [00:06<02:25,  6.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3021249771118164 Batch_id=40 Accuracy=11.32:   4%|▍         | 41/938 [00:06<02:20,  6.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302088975906372 Batch_id=41 Accuracy=11.38:   4%|▍         | 41/938 [00:06<02:20,  6.37it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302088975906372 Batch_id=41 Accuracy=11.38:   4%|▍         | 42/938 [00:06<02:16,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301546096801758 Batch_id=42 Accuracy=11.52:   4%|▍         | 42/938 [00:07<02:16,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301546096801758 Batch_id=42 Accuracy=11.52:   5%|▍         | 43/938 [00:07<02:12,  6.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3021481037139893 Batch_id=43 Accuracy=11.65:   5%|▍         | 43/938 [00:07<02:12,  6.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3021481037139893 Batch_id=43 Accuracy=11.65:   5%|▍         | 44/938 [00:07<02:11,  6.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302156925201416 Batch_id=44 Accuracy=11.60:   5%|▍         | 44/938 [00:07<02:11,  6.77it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302156925201416 Batch_id=44 Accuracy=11.60:   5%|▍         | 45/938 [00:07<02:19,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3022732734680176 Batch_id=45 Accuracy=11.62:   5%|▍         | 45/938 [00:07<02:19,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3022732734680176 Batch_id=45 Accuracy=11.62:   5%|▍         | 46/938 [00:07<02:12,  6.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3020927906036377 Batch_id=46 Accuracy=11.70:   5%|▍         | 46/938 [00:07<02:12,  6.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3020927906036377 Batch_id=46 Accuracy=11.70:   5%|▌         | 47/938 [00:07<02:09,  6.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3020153045654297 Batch_id=47 Accuracy=11.78:   5%|▌         | 47/938 [00:07<02:09,  6.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3020153045654297 Batch_id=47 Accuracy=11.78:   5%|▌         | 48/938 [00:07<02:08,  6.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3022232055664062 Batch_id=48 Accuracy=11.96:   5%|▌         | 48/938 [00:07<02:08,  6.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3022232055664062 Batch_id=48 Accuracy=11.96:   5%|▌         | 49/938 [00:07<02:10,  6.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3019330501556396 Batch_id=49 Accuracy=12.03:   5%|▌         | 49/938 [00:08<02:10,  6.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3019330501556396 Batch_id=49 Accuracy=12.03:   5%|▌         | 50/938 [00:08<02:14,  6.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301684856414795 Batch_id=50 Accuracy=12.25:   5%|▌         | 50/938 [00:08<02:14,  6.60it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301684856414795 Batch_id=50 Accuracy=12.25:   5%|▌         | 51/938 [00:08<02:20,  6.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302156686782837 Batch_id=51 Accuracy=12.29:   5%|▌         | 51/938 [00:08<02:20,  6.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302156686782837 Batch_id=51 Accuracy=12.29:   6%|▌         | 52/938 [00:08<02:24,  6.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301877737045288 Batch_id=52 Accuracy=12.44:   6%|▌         | 52/938 [00:08<02:24,  6.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301877737045288 Batch_id=52 Accuracy=12.44:   6%|▌         | 53/938 [00:08<02:18,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3017683029174805 Batch_id=53 Accuracy=12.62:   6%|▌         | 53/938 [00:08<02:18,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3017683029174805 Batch_id=53 Accuracy=12.62:   6%|▌         | 54/938 [00:08<02:26,  6.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301578998565674 Batch_id=54 Accuracy=12.76:   6%|▌         | 54/938 [00:08<02:26,  6.04it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301578998565674 Batch_id=54 Accuracy=12.76:   6%|▌         | 55/938 [00:08<02:28,  5.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301863670349121 Batch_id=55 Accuracy=12.86:   6%|▌         | 55/938 [00:09<02:28,  5.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301863670349121 Batch_id=55 Accuracy=12.86:   6%|▌         | 56/938 [00:09<02:24,  6.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301293134689331 Batch_id=56 Accuracy=12.99:   6%|▌         | 56/938 [00:09<02:24,  6.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301293134689331 Batch_id=56 Accuracy=12.99:   6%|▌         | 57/938 [00:09<02:18,  6.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3014943599700928 Batch_id=57 Accuracy=13.12:   6%|▌         | 57/938 [00:09<02:18,  6.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3014943599700928 Batch_id=57 Accuracy=13.12:   6%|▌         | 58/938 [00:09<02:13,  6.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3013579845428467 Batch_id=58 Accuracy=13.14:   6%|▌         | 58/938 [00:09<02:13,  6.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3013579845428467 Batch_id=58 Accuracy=13.14:   6%|▋         | 59/938 [00:09<02:14,  6.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302206039428711 Batch_id=59 Accuracy=13.10:   6%|▋         | 59/938 [00:09<02:14,  6.54it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.302206039428711 Batch_id=59 Accuracy=13.10:   6%|▋         | 60/938 [00:09<02:12,  6.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3022232055664062 Batch_id=60 Accuracy=13.09:   6%|▋         | 60/938 [00:09<02:12,  6.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3022232055664062 Batch_id=60 Accuracy=13.09:   7%|▋         | 61/938 [00:09<02:06,  6.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3018720149993896 Batch_id=61 Accuracy=13.26:   7%|▋         | 61/938 [00:09<02:06,  6.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3018720149993896 Batch_id=61 Accuracy=13.26:   7%|▋         | 62/938 [00:09<02:06,  6.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3016209602355957 Batch_id=62 Accuracy=13.39:   7%|▋         | 62/938 [00:10<02:06,  6.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3016209602355957 Batch_id=62 Accuracy=13.39:   7%|▋         | 63/938 [00:10<02:15,  6.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301415205001831 Batch_id=63 Accuracy=13.53:   7%|▋         | 63/938 [00:10<02:15,  6.45it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301415205001831 Batch_id=63 Accuracy=13.53:   7%|▋         | 64/938 [00:10<02:21,  6.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301905393600464 Batch_id=64 Accuracy=13.61:   7%|▋         | 64/938 [00:10<02:21,  6.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301905393600464 Batch_id=64 Accuracy=13.61:   7%|▋         | 65/938 [00:10<02:18,  6.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301821231842041 Batch_id=65 Accuracy=13.57:   7%|▋         | 65/938 [00:10<02:18,  6.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301821231842041 Batch_id=65 Accuracy=13.57:   7%|▋         | 66/938 [00:10<02:14,  6.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3011474609375 Batch_id=66 Accuracy=13.62:   7%|▋         | 66/938 [00:10<02:14,  6.46it/s]  \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3011474609375 Batch_id=66 Accuracy=13.62:   7%|▋         | 67/938 [00:10<02:09,  6.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3020951747894287 Batch_id=67 Accuracy=13.63:   7%|▋         | 67/938 [00:10<02:09,  6.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3020951747894287 Batch_id=67 Accuracy=13.63:   7%|▋         | 68/938 [00:10<02:11,  6.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3016200065612793 Batch_id=68 Accuracy=13.59:   7%|▋         | 68/938 [00:11<02:11,  6.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3016200065612793 Batch_id=68 Accuracy=13.59:   7%|▋         | 69/938 [00:11<02:16,  6.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3003556728363037 Batch_id=69 Accuracy=13.82:   7%|▋         | 69/938 [00:11<02:16,  6.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3003556728363037 Batch_id=69 Accuracy=13.82:   7%|▋         | 70/938 [00:11<02:15,  6.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3018245697021484 Batch_id=70 Accuracy=13.78:   7%|▋         | 70/938 [00:11<02:15,  6.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3018245697021484 Batch_id=70 Accuracy=13.78:   8%|▊         | 71/938 [00:11<02:13,  6.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301126003265381 Batch_id=71 Accuracy=13.91:   8%|▊         | 71/938 [00:11<02:13,  6.48it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301126003265381 Batch_id=71 Accuracy=13.91:   8%|▊         | 72/938 [00:11<02:18,  6.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301220655441284 Batch_id=72 Accuracy=13.98:   8%|▊         | 72/938 [00:11<02:18,  6.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301220655441284 Batch_id=72 Accuracy=13.98:   8%|▊         | 73/938 [00:11<02:16,  6.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300776481628418 Batch_id=73 Accuracy=14.10:   8%|▊         | 73/938 [00:11<02:16,  6.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300776481628418 Batch_id=73 Accuracy=14.10:   8%|▊         | 74/938 [00:11<02:11,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3009042739868164 Batch_id=74 Accuracy=14.25:   8%|▊         | 74/938 [00:12<02:11,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3009042739868164 Batch_id=74 Accuracy=14.25:   8%|▊         | 75/938 [00:12<02:11,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301466226577759 Batch_id=75 Accuracy=14.25:   8%|▊         | 75/938 [00:12<02:11,  6.58it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301466226577759 Batch_id=75 Accuracy=14.25:   8%|▊         | 76/938 [00:12<02:08,  6.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300429582595825 Batch_id=76 Accuracy=14.45:   8%|▊         | 76/938 [00:12<02:08,  6.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300429582595825 Batch_id=76 Accuracy=14.45:   8%|▊         | 77/938 [00:12<02:10,  6.61it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=2.301309585571289 Batch_id=77 Accuracy=14.50:   8%|▊         | 77/938 [00:12<02:10,  6.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.301309585571289 Batch_id=77 Accuracy=14.50:   8%|▊         | 78/938 [00:12<02:15,  6.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300262451171875 Batch_id=78 Accuracy=14.64:   8%|▊         | 78/938 [00:12<02:15,  6.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300262451171875 Batch_id=78 Accuracy=14.64:   8%|▊         | 79/938 [00:12<02:15,  6.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300861358642578 Batch_id=79 Accuracy=14.65:   8%|▊         | 79/938 [00:12<02:15,  6.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300861358642578 Batch_id=79 Accuracy=14.65:   9%|▊         | 80/938 [00:12<02:13,  6.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300668239593506 Batch_id=80 Accuracy=14.66:   9%|▊         | 80/938 [00:12<02:13,  6.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300668239593506 Batch_id=80 Accuracy=14.66:   9%|▊         | 81/938 [00:12<02:23,  5.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3015012741088867 Batch_id=81 Accuracy=14.63:   9%|▊         | 81/938 [00:13<02:23,  5.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3015012741088867 Batch_id=81 Accuracy=14.63:   9%|▊         | 82/938 [00:13<02:20,  6.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300804376602173 Batch_id=82 Accuracy=14.70:   9%|▊         | 82/938 [00:13<02:20,  6.11it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300804376602173 Batch_id=82 Accuracy=14.70:   9%|▉         | 83/938 [00:13<02:15,  6.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3008387088775635 Batch_id=83 Accuracy=14.75:   9%|▉         | 83/938 [00:13<02:15,  6.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3008387088775635 Batch_id=83 Accuracy=14.75:   9%|▉         | 84/938 [00:13<02:14,  6.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3000872135162354 Batch_id=84 Accuracy=14.83:   9%|▉         | 84/938 [00:13<02:14,  6.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3000872135162354 Batch_id=84 Accuracy=14.83:   9%|▉         | 85/938 [00:13<02:09,  6.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3003015518188477 Batch_id=85 Accuracy=14.86:   9%|▉         | 85/938 [00:13<02:09,  6.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3003015518188477 Batch_id=85 Accuracy=14.86:   9%|▉         | 86/938 [00:13<02:05,  6.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3001441955566406 Batch_id=86 Accuracy=14.92:   9%|▉         | 86/938 [00:13<02:05,  6.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3001441955566406 Batch_id=86 Accuracy=14.92:   9%|▉         | 87/938 [00:13<02:07,  6.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3011434078216553 Batch_id=87 Accuracy=14.95:   9%|▉         | 87/938 [00:14<02:07,  6.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.3011434078216553 Batch_id=87 Accuracy=14.95:   9%|▉         | 88/938 [00:14<02:05,  6.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300607681274414 Batch_id=88 Accuracy=14.96:   9%|▉         | 88/938 [00:14<02:05,  6.78it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300607681274414 Batch_id=88 Accuracy=14.96:   9%|▉         | 89/938 [00:14<02:14,  6.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300276041030884 Batch_id=89 Accuracy=14.98:   9%|▉         | 89/938 [00:14<02:14,  6.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.300276041030884 Batch_id=89 Accuracy=14.98:  10%|▉         | 90/938 [00:14<02:23,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2998147010803223 Batch_id=90 Accuracy=15.01:  10%|▉         | 90/938 [00:14<02:23,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2998147010803223 Batch_id=90 Accuracy=15.01:  10%|▉         | 91/938 [00:14<02:18,  6.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2998852729797363 Batch_id=91 Accuracy=15.06:  10%|▉         | 91/938 [00:14<02:18,  6.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2998852729797363 Batch_id=91 Accuracy=15.06:  10%|▉         | 92/938 [00:14<02:14,  6.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2988576889038086 Batch_id=92 Accuracy=15.14:  10%|▉         | 92/938 [00:14<02:14,  6.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2988576889038086 Batch_id=92 Accuracy=15.14:  10%|▉         | 93/938 [00:14<02:16,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.299204111099243 Batch_id=93 Accuracy=15.09:  10%|▉         | 93/938 [00:15<02:16,  6.21it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.299204111099243 Batch_id=93 Accuracy=15.09:  10%|█         | 94/938 [00:15<02:17,  6.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2989351749420166 Batch_id=94 Accuracy=15.18:  10%|█         | 94/938 [00:15<02:17,  6.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2989351749420166 Batch_id=94 Accuracy=15.18:  10%|█         | 95/938 [00:15<02:15,  6.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2985680103302 Batch_id=95 Accuracy=15.25:  10%|█         | 95/938 [00:15<02:15,  6.24it/s]   \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2985680103302 Batch_id=95 Accuracy=15.25:  10%|█         | 96/938 [00:15<02:16,  6.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2994182109832764 Batch_id=96 Accuracy=15.37:  10%|█         | 96/938 [00:15<02:16,  6.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2994182109832764 Batch_id=96 Accuracy=15.37:  10%|█         | 97/938 [00:15<02:15,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298348903656006 Batch_id=97 Accuracy=15.45:  10%|█         | 97/938 [00:15<02:15,  6.21it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298348903656006 Batch_id=97 Accuracy=15.45:  10%|█         | 98/938 [00:15<02:17,  6.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2980306148529053 Batch_id=98 Accuracy=15.56:  10%|█         | 98/938 [00:15<02:17,  6.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2980306148529053 Batch_id=98 Accuracy=15.56:  11%|█         | 99/938 [00:15<02:15,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298609495162964 Batch_id=99 Accuracy=15.69:  11%|█         | 99/938 [00:15<02:15,  6.21it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298609495162964 Batch_id=99 Accuracy=15.69:  11%|█         | 100/938 [00:15<02:08,  6.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2994446754455566 Batch_id=100 Accuracy=15.69:  11%|█         | 100/938 [00:16<02:08,  6.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2994446754455566 Batch_id=100 Accuracy=15.69:  11%|█         | 101/938 [00:16<02:13,  6.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.299330472946167 Batch_id=101 Accuracy=15.70:  11%|█         | 101/938 [00:16<02:13,  6.26it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.299330472946167 Batch_id=101 Accuracy=15.70:  11%|█         | 102/938 [00:16<02:21,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2989814281463623 Batch_id=102 Accuracy=15.66:  11%|█         | 102/938 [00:16<02:21,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2989814281463623 Batch_id=102 Accuracy=15.66:  11%|█         | 103/938 [00:16<02:14,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298527717590332 Batch_id=103 Accuracy=15.70:  11%|█         | 103/938 [00:16<02:14,  6.21it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298527717590332 Batch_id=103 Accuracy=15.70:  11%|█         | 104/938 [00:16<02:06,  6.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2992944717407227 Batch_id=104 Accuracy=15.68:  11%|█         | 104/938 [00:16<02:06,  6.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2992944717407227 Batch_id=104 Accuracy=15.68:  11%|█         | 105/938 [00:16<02:06,  6.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298154354095459 Batch_id=105 Accuracy=15.74:  11%|█         | 105/938 [00:16<02:06,  6.60it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298154354095459 Batch_id=105 Accuracy=15.74:  11%|█▏        | 106/938 [00:16<02:07,  6.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298762559890747 Batch_id=106 Accuracy=15.76:  11%|█▏        | 106/938 [00:17<02:07,  6.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.298762559890747 Batch_id=106 Accuracy=15.76:  11%|█▏        | 107/938 [00:17<02:07,  6.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2968757152557373 Batch_id=107 Accuracy=15.83:  11%|█▏        | 107/938 [00:17<02:07,  6.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2968757152557373 Batch_id=107 Accuracy=15.83:  12%|█▏        | 108/938 [00:17<02:09,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2968909740448 Batch_id=108 Accuracy=15.84:  12%|█▏        | 108/938 [00:17<02:09,  6.40it/s]   \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2968909740448 Batch_id=108 Accuracy=15.84:  12%|█▏        | 109/938 [00:17<02:09,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.296781063079834 Batch_id=109 Accuracy=15.91:  12%|█▏        | 109/938 [00:17<02:09,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.296781063079834 Batch_id=109 Accuracy=15.91:  12%|█▏        | 110/938 [00:17<02:13,  6.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2939846515655518 Batch_id=110 Accuracy=16.09:  12%|█▏        | 110/938 [00:17<02:13,  6.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2939846515655518 Batch_id=110 Accuracy=16.09:  12%|█▏        | 111/938 [00:17<02:17,  6.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2977304458618164 Batch_id=111 Accuracy=16.10:  12%|█▏        | 111/938 [00:17<02:17,  6.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2977304458618164 Batch_id=111 Accuracy=16.10:  12%|█▏        | 112/938 [00:17<02:33,  5.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.29567551612854 Batch_id=112 Accuracy=16.14:  12%|█▏        | 112/938 [00:18<02:33,  5.39it/s]  \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.29567551612854 Batch_id=112 Accuracy=16.14:  12%|█▏        | 113/938 [00:18<02:41,  5.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2950079441070557 Batch_id=113 Accuracy=16.24:  12%|█▏        | 113/938 [00:18<02:41,  5.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2950079441070557 Batch_id=113 Accuracy=16.24:  12%|█▏        | 114/938 [00:18<02:31,  5.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2942943572998047 Batch_id=114 Accuracy=16.29:  12%|█▏        | 114/938 [00:18<02:31,  5.43it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=2.2942943572998047 Batch_id=114 Accuracy=16.29:  12%|█▏        | 115/938 [00:18<02:24,  5.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2958290576934814 Batch_id=115 Accuracy=16.34:  12%|█▏        | 115/938 [00:18<02:24,  5.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2958290576934814 Batch_id=115 Accuracy=16.34:  12%|█▏        | 116/938 [00:18<02:27,  5.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2934019565582275 Batch_id=116 Accuracy=16.35:  12%|█▏        | 116/938 [00:18<02:27,  5.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2934019565582275 Batch_id=116 Accuracy=16.35:  12%|█▏        | 117/938 [00:18<02:28,  5.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2934024333953857 Batch_id=117 Accuracy=16.38:  12%|█▏        | 117/938 [00:19<02:28,  5.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2934024333953857 Batch_id=117 Accuracy=16.38:  13%|█▎        | 118/938 [00:19<02:33,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2912425994873047 Batch_id=118 Accuracy=16.45:  13%|█▎        | 118/938 [00:19<02:33,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2912425994873047 Batch_id=118 Accuracy=16.45:  13%|█▎        | 119/938 [00:19<02:35,  5.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.292933225631714 Batch_id=119 Accuracy=16.48:  13%|█▎        | 119/938 [00:19<02:35,  5.26it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.292933225631714 Batch_id=119 Accuracy=16.48:  13%|█▎        | 120/938 [00:19<02:25,  5.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.29107666015625 Batch_id=120 Accuracy=16.55:  13%|█▎        | 120/938 [00:19<02:25,  5.62it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.29107666015625 Batch_id=120 Accuracy=16.55:  13%|█▎        | 121/938 [00:19<02:16,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.292698621749878 Batch_id=121 Accuracy=16.55:  13%|█▎        | 121/938 [00:19<02:16,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.292698621749878 Batch_id=121 Accuracy=16.55:  13%|█▎        | 122/938 [00:19<02:29,  5.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.289733409881592 Batch_id=122 Accuracy=16.60:  13%|█▎        | 122/938 [00:19<02:29,  5.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.289733409881592 Batch_id=122 Accuracy=16.60:  13%|█▎        | 123/938 [00:19<02:23,  5.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.285374641418457 Batch_id=123 Accuracy=16.66:  13%|█▎        | 123/938 [00:20<02:23,  5.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.285374641418457 Batch_id=123 Accuracy=16.66:  13%|█▎        | 124/938 [00:20<02:27,  5.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.284616708755493 Batch_id=124 Accuracy=16.70:  13%|█▎        | 124/938 [00:20<02:27,  5.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.284616708755493 Batch_id=124 Accuracy=16.70:  13%|█▎        | 125/938 [00:20<02:32,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.285865545272827 Batch_id=125 Accuracy=16.72:  13%|█▎        | 125/938 [00:20<02:32,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.285865545272827 Batch_id=125 Accuracy=16.72:  13%|█▎        | 126/938 [00:20<02:27,  5.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2849080562591553 Batch_id=126 Accuracy=16.72:  13%|█▎        | 126/938 [00:20<02:27,  5.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2849080562591553 Batch_id=126 Accuracy=16.72:  14%|█▎        | 127/938 [00:20<02:17,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2858684062957764 Batch_id=127 Accuracy=16.69:  14%|█▎        | 127/938 [00:20<02:17,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2858684062957764 Batch_id=127 Accuracy=16.69:  14%|█▎        | 128/938 [00:20<02:09,  6.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2810685634613037 Batch_id=128 Accuracy=16.75:  14%|█▎        | 128/938 [00:20<02:09,  6.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2810685634613037 Batch_id=128 Accuracy=16.75:  14%|█▍        | 129/938 [00:20<02:03,  6.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.276975393295288 Batch_id=129 Accuracy=16.83:  14%|█▍        | 129/938 [00:21<02:03,  6.54it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.276975393295288 Batch_id=129 Accuracy=16.83:  14%|█▍        | 130/938 [00:21<02:05,  6.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2796266078948975 Batch_id=130 Accuracy=16.85:  14%|█▍        | 130/938 [00:21<02:05,  6.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2796266078948975 Batch_id=130 Accuracy=16.85:  14%|█▍        | 131/938 [00:21<02:05,  6.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2700092792510986 Batch_id=131 Accuracy=16.99:  14%|█▍        | 131/938 [00:21<02:05,  6.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2700092792510986 Batch_id=131 Accuracy=16.99:  14%|█▍        | 132/938 [00:21<02:05,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2695422172546387 Batch_id=132 Accuracy=17.02:  14%|█▍        | 132/938 [00:21<02:05,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2695422172546387 Batch_id=132 Accuracy=17.02:  14%|█▍        | 133/938 [00:21<02:09,  6.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.273674488067627 Batch_id=133 Accuracy=17.05:  14%|█▍        | 133/938 [00:21<02:09,  6.20it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.273674488067627 Batch_id=133 Accuracy=17.05:  14%|█▍        | 134/938 [00:21<02:12,  6.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.269030809402466 Batch_id=134 Accuracy=17.05:  14%|█▍        | 134/938 [00:21<02:12,  6.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.269030809402466 Batch_id=134 Accuracy=17.05:  14%|█▍        | 135/938 [00:21<02:14,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.242547035217285 Batch_id=135 Accuracy=17.18:  14%|█▍        | 135/938 [00:22<02:14,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.242547035217285 Batch_id=135 Accuracy=17.18:  14%|█▍        | 136/938 [00:22<02:18,  5.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.248720169067383 Batch_id=136 Accuracy=17.20:  14%|█▍        | 136/938 [00:22<02:18,  5.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.248720169067383 Batch_id=136 Accuracy=17.20:  15%|█▍        | 137/938 [00:22<02:40,  4.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.227320909500122 Batch_id=137 Accuracy=17.28:  15%|█▍        | 137/938 [00:22<02:40,  4.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.227320909500122 Batch_id=137 Accuracy=17.28:  15%|█▍        | 138/938 [00:22<03:08,  4.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2175183296203613 Batch_id=138 Accuracy=17.39:  15%|█▍        | 138/938 [00:22<03:08,  4.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2175183296203613 Batch_id=138 Accuracy=17.39:  15%|█▍        | 139/938 [00:22<03:15,  4.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2042758464813232 Batch_id=139 Accuracy=17.44:  15%|█▍        | 139/938 [00:23<03:15,  4.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.2042758464813232 Batch_id=139 Accuracy=17.44:  15%|█▍        | 140/938 [00:23<03:16,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1886277198791504 Batch_id=140 Accuracy=17.48:  15%|█▍        | 140/938 [00:23<03:16,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1886277198791504 Batch_id=140 Accuracy=17.48:  15%|█▌        | 141/938 [00:23<03:21,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1703929901123047 Batch_id=141 Accuracy=17.52:  15%|█▌        | 141/938 [00:23<03:21,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1703929901123047 Batch_id=141 Accuracy=17.52:  15%|█▌        | 142/938 [00:23<03:20,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1703765392303467 Batch_id=142 Accuracy=17.52:  15%|█▌        | 142/938 [00:23<03:20,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1703765392303467 Batch_id=142 Accuracy=17.52:  15%|█▌        | 143/938 [00:23<03:23,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1128597259521484 Batch_id=143 Accuracy=17.61:  15%|█▌        | 143/938 [00:24<03:23,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1128597259521484 Batch_id=143 Accuracy=17.61:  15%|█▌        | 144/938 [00:24<03:30,  3.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0309019088745117 Batch_id=144 Accuracy=17.74:  15%|█▌        | 144/938 [00:24<03:30,  3.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0309019088745117 Batch_id=144 Accuracy=17.74:  15%|█▌        | 145/938 [00:24<03:30,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.9605891704559326 Batch_id=145 Accuracy=17.92:  15%|█▌        | 145/938 [00:24<03:30,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.9605891704559326 Batch_id=145 Accuracy=17.92:  16%|█▌        | 146/938 [00:24<03:45,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.852645993232727 Batch_id=146 Accuracy=18.12:  16%|█▌        | 146/938 [00:25<03:45,  3.52it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=1.852645993232727 Batch_id=146 Accuracy=18.12:  16%|█▌        | 147/938 [00:25<03:46,  3.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.611938238143921 Batch_id=147 Accuracy=18.37:  16%|█▌        | 147/938 [00:25<03:46,  3.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.611938238143921 Batch_id=147 Accuracy=18.37:  16%|█▌        | 148/938 [00:25<03:43,  3.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.5211108922958374 Batch_id=148 Accuracy=18.60:  16%|█▌        | 148/938 [00:25<03:43,  3.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.5211108922958374 Batch_id=148 Accuracy=18.60:  16%|█▌        | 149/938 [00:25<03:36,  3.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.2124613523483276 Batch_id=149 Accuracy=18.91:  16%|█▌        | 149/938 [00:25<03:36,  3.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.2124613523483276 Batch_id=149 Accuracy=18.91:  16%|█▌        | 150/938 [00:25<03:22,  3.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.2543689012527466 Batch_id=150 Accuracy=19.16:  16%|█▌        | 150/938 [00:26<03:22,  3.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.2543689012527466 Batch_id=150 Accuracy=19.16:  16%|█▌        | 151/938 [00:26<03:33,  3.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.0617507696151733 Batch_id=151 Accuracy=19.44:  16%|█▌        | 151/938 [00:26<03:33,  3.69it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0617507696151733 Batch_id=151 Accuracy=19.44:  16%|█▌        | 152/938 [00:26<03:21,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.3132652044296265 Batch_id=152 Accuracy=19.81:  16%|█▌        | 152/938 [00:26<03:21,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.3132652044296265 Batch_id=152 Accuracy=19.81:  16%|█▋        | 153/938 [00:26<03:29,  3.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7642717361450195 Batch_id=153 Accuracy=20.07:  16%|█▋        | 153/938 [00:26<03:29,  3.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7642717361450195 Batch_id=153 Accuracy=20.07:  16%|█▋        | 154/938 [00:26<03:20,  3.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0219991207122803 Batch_id=154 Accuracy=20.29:  16%|█▋        | 154/938 [00:27<03:20,  3.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0219991207122803 Batch_id=154 Accuracy=20.29:  17%|█▋        | 155/938 [00:27<03:04,  4.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.9914127588272095 Batch_id=155 Accuracy=20.50:  17%|█▋        | 155/938 [00:27<03:04,  4.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.9914127588272095 Batch_id=155 Accuracy=20.50:  17%|█▋        | 156/938 [00:27<03:05,  4.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.6558202505111694 Batch_id=156 Accuracy=20.71:  17%|█▋        | 156/938 [00:27<03:05,  4.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.6558202505111694 Batch_id=156 Accuracy=20.71:  17%|█▋        | 157/938 [00:27<03:10,  4.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.066545248031616 Batch_id=157 Accuracy=20.81:  17%|█▋        | 157/938 [00:27<03:10,  4.09it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.066545248031616 Batch_id=157 Accuracy=20.81:  17%|█▋        | 158/938 [00:27<03:18,  3.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1500043869018555 Batch_id=158 Accuracy=20.89:  17%|█▋        | 158/938 [00:28<03:18,  3.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1500043869018555 Batch_id=158 Accuracy=20.89:  17%|█▋        | 159/938 [00:28<03:32,  3.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1430718898773193 Batch_id=159 Accuracy=20.97:  17%|█▋        | 159/938 [00:28<03:32,  3.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.1430718898773193 Batch_id=159 Accuracy=20.97:  17%|█▋        | 160/938 [00:28<03:39,  3.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.112553358078003 Batch_id=160 Accuracy=21.07:  17%|█▋        | 160/938 [00:28<03:39,  3.55it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.112553358078003 Batch_id=160 Accuracy=21.07:  17%|█▋        | 161/938 [00:28<03:50,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0465288162231445 Batch_id=161 Accuracy=21.15:  17%|█▋        | 161/938 [00:29<03:50,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0465288162231445 Batch_id=161 Accuracy=21.15:  17%|█▋        | 162/938 [00:29<03:45,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0754616260528564 Batch_id=162 Accuracy=21.24:  17%|█▋        | 162/938 [00:29<03:45,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0754616260528564 Batch_id=162 Accuracy=21.24:  17%|█▋        | 163/938 [00:29<03:43,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.015146255493164 Batch_id=163 Accuracy=21.29:  17%|█▋        | 163/938 [00:29<03:43,  3.47it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=2.015146255493164 Batch_id=163 Accuracy=21.29:  17%|█▋        | 164/938 [00:29<03:18,  3.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.8210163116455078 Batch_id=164 Accuracy=21.44:  17%|█▋        | 164/938 [00:29<03:18,  3.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.8210163116455078 Batch_id=164 Accuracy=21.44:  18%|█▊        | 165/938 [00:29<02:54,  4.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0953845977783203 Batch_id=165 Accuracy=21.52:  18%|█▊        | 165/938 [00:29<02:54,  4.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=2.0953845977783203 Batch_id=165 Accuracy=21.52:  18%|█▊        | 166/938 [00:29<02:47,  4.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.8193329572677612 Batch_id=166 Accuracy=21.65:  18%|█▊        | 166/938 [00:30<02:47,  4.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.8193329572677612 Batch_id=166 Accuracy=21.65:  18%|█▊        | 167/938 [00:30<02:37,  4.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7887150049209595 Batch_id=167 Accuracy=21.76:  18%|█▊        | 167/938 [00:30<02:37,  4.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7887150049209595 Batch_id=167 Accuracy=21.76:  18%|█▊        | 168/938 [00:30<02:24,  5.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7393684387207031 Batch_id=168 Accuracy=21.89:  18%|█▊        | 168/938 [00:30<02:24,  5.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7393684387207031 Batch_id=168 Accuracy=21.89:  18%|█▊        | 169/938 [00:30<02:17,  5.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.833823561668396 Batch_id=169 Accuracy=21.98:  18%|█▊        | 169/938 [00:30<02:17,  5.60it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=1.833823561668396 Batch_id=169 Accuracy=21.98:  18%|█▊        | 170/938 [00:30<02:12,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7471758127212524 Batch_id=170 Accuracy=22.06:  18%|█▊        | 170/938 [00:30<02:12,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7471758127212524 Batch_id=170 Accuracy=22.06:  18%|█▊        | 171/938 [00:30<02:14,  5.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7919540405273438 Batch_id=171 Accuracy=22.13:  18%|█▊        | 171/938 [00:30<02:14,  5.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.7919540405273438 Batch_id=171 Accuracy=22.13:  18%|█▊        | 172/938 [00:30<02:16,  5.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.432715654373169 Batch_id=172 Accuracy=22.33:  18%|█▊        | 172/938 [00:31<02:16,  5.60it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=1.432715654373169 Batch_id=172 Accuracy=22.33:  18%|█▊        | 173/938 [00:31<02:11,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.3501529693603516 Batch_id=173 Accuracy=22.53:  18%|█▊        | 173/938 [00:31<02:11,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.3501529693603516 Batch_id=173 Accuracy=22.53:  19%|█▊        | 174/938 [00:31<02:10,  5.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.133913278579712 Batch_id=174 Accuracy=22.80:  19%|█▊        | 174/938 [00:31<02:10,  5.87it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=1.133913278579712 Batch_id=174 Accuracy=22.80:  19%|█▊        | 175/938 [00:31<02:08,  5.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.4082647562026978 Batch_id=175 Accuracy=23.02:  19%|█▊        | 175/938 [00:31<02:08,  5.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.4082647562026978 Batch_id=175 Accuracy=23.02:  19%|█▉        | 176/938 [00:31<02:13,  5.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.8055819869041443 Batch_id=176 Accuracy=23.31:  19%|█▉        | 176/938 [00:31<02:13,  5.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.8055819869041443 Batch_id=176 Accuracy=23.31:  19%|█▉        | 177/938 [00:31<02:16,  5.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6476306319236755 Batch_id=177 Accuracy=23.60:  19%|█▉        | 177/938 [00:31<02:16,  5.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6476306319236755 Batch_id=177 Accuracy=23.60:  19%|█▉        | 178/938 [00:32<02:12,  5.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.085398554801941 Batch_id=178 Accuracy=23.86:  19%|█▉        | 178/938 [00:32<02:12,  5.74it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=1.085398554801941 Batch_id=178 Accuracy=23.86:  19%|█▉        | 179/938 [00:32<02:09,  5.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.8176915049552917 Batch_id=179 Accuracy=24.17:  19%|█▉        | 179/938 [00:32<02:09,  5.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.8176915049552917 Batch_id=179 Accuracy=24.17:  19%|█▉        | 180/938 [00:32<02:27,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7954107522964478 Batch_id=180 Accuracy=24.46:  19%|█▉        | 180/938 [00:32<02:27,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7954107522964478 Batch_id=180 Accuracy=24.46:  19%|█▉        | 181/938 [00:32<02:23,  5.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7694856524467468 Batch_id=181 Accuracy=24.75:  19%|█▉        | 181/938 [00:32<02:23,  5.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7694856524467468 Batch_id=181 Accuracy=24.75:  19%|█▉        | 182/938 [00:32<02:27,  5.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7362634539604187 Batch_id=182 Accuracy=25.04:  19%|█▉        | 182/938 [00:33<02:27,  5.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7362634539604187 Batch_id=182 Accuracy=25.04:  20%|█▉        | 183/938 [00:33<02:34,  4.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7284488081932068 Batch_id=183 Accuracy=25.34:  20%|█▉        | 183/938 [00:33<02:34,  4.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7284488081932068 Batch_id=183 Accuracy=25.34:  20%|█▉        | 184/938 [00:33<02:43,  4.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7799119353294373 Batch_id=184 Accuracy=25.59:  20%|█▉        | 184/938 [00:33<02:43,  4.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7799119353294373 Batch_id=184 Accuracy=25.59:  20%|█▉        | 185/938 [00:33<02:51,  4.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6726791858673096 Batch_id=185 Accuracy=25.87:  20%|█▉        | 185/938 [00:33<02:51,  4.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6726791858673096 Batch_id=185 Accuracy=25.87:  20%|█▉        | 186/938 [00:33<02:54,  4.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6555314064025879 Batch_id=186 Accuracy=26.19:  20%|█▉        | 186/938 [00:33<02:54,  4.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6555314064025879 Batch_id=186 Accuracy=26.19:  20%|█▉        | 187/938 [00:34<02:54,  4.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.610706627368927 Batch_id=187 Accuracy=26.47:  20%|█▉        | 187/938 [00:34<02:54,  4.31it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.610706627368927 Batch_id=187 Accuracy=26.47:  20%|██        | 188/938 [00:34<02:40,  4.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=1.16048264503479 Batch_id=188 Accuracy=26.67:  20%|██        | 188/938 [00:34<02:40,  4.67it/s] \u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.16048264503479 Batch_id=188 Accuracy=26.67:  20%|██        | 189/938 [00:34<02:25,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6720511317253113 Batch_id=189 Accuracy=26.99:  20%|██        | 189/938 [00:34<02:25,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6720511317253113 Batch_id=189 Accuracy=26.99:  20%|██        | 190/938 [00:34<02:18,  5.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.792354166507721 Batch_id=190 Accuracy=27.19:  20%|██        | 190/938 [00:34<02:18,  5.42it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.792354166507721 Batch_id=190 Accuracy=27.19:  20%|██        | 191/938 [00:34<02:14,  5.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7171040177345276 Batch_id=191 Accuracy=27.45:  20%|██        | 191/938 [00:34<02:14,  5.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7171040177345276 Batch_id=191 Accuracy=27.45:  20%|██        | 192/938 [00:34<02:16,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.820227324962616 Batch_id=192 Accuracy=27.67:  20%|██        | 192/938 [00:35<02:16,  5.45it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.820227324962616 Batch_id=192 Accuracy=27.67:  21%|██        | 193/938 [00:35<02:24,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7407616376876831 Batch_id=193 Accuracy=27.96:  21%|██        | 193/938 [00:35<02:24,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7407616376876831 Batch_id=193 Accuracy=27.96:  21%|██        | 194/938 [00:35<02:20,  5.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5927851796150208 Batch_id=194 Accuracy=28.24:  21%|██        | 194/938 [00:35<02:20,  5.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5927851796150208 Batch_id=194 Accuracy=28.24:  21%|██        | 195/938 [00:35<02:18,  5.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5922807455062866 Batch_id=195 Accuracy=28.50:  21%|██        | 195/938 [00:35<02:18,  5.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5922807455062866 Batch_id=195 Accuracy=28.50:  21%|██        | 196/938 [00:35<02:14,  5.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5615919828414917 Batch_id=196 Accuracy=28.75:  21%|██        | 196/938 [00:35<02:14,  5.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5615919828414917 Batch_id=196 Accuracy=28.75:  21%|██        | 197/938 [00:35<02:16,  5.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5954778790473938 Batch_id=197 Accuracy=29.02:  21%|██        | 197/938 [00:36<02:16,  5.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5954778790473938 Batch_id=197 Accuracy=29.02:  21%|██        | 198/938 [00:36<02:30,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5502417683601379 Batch_id=198 Accuracy=29.29:  21%|██        | 198/938 [00:36<02:30,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5502417683601379 Batch_id=198 Accuracy=29.29:  21%|██        | 199/938 [00:36<02:38,  4.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3468427360057831 Batch_id=199 Accuracy=29.58:  21%|██        | 199/938 [00:36<02:38,  4.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3468427360057831 Batch_id=199 Accuracy=29.58:  21%|██▏       | 200/938 [00:36<02:50,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7595342993736267 Batch_id=200 Accuracy=29.83:  21%|██▏       | 200/938 [00:36<02:50,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7595342993736267 Batch_id=200 Accuracy=29.83:  21%|██▏       | 201/938 [00:36<02:52,  4.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6975883841514587 Batch_id=201 Accuracy=30.08:  21%|██▏       | 201/938 [00:37<02:52,  4.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6975883841514587 Batch_id=201 Accuracy=30.08:  22%|██▏       | 202/938 [00:37<02:55,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5139197111129761 Batch_id=202 Accuracy=30.33:  22%|██▏       | 202/938 [00:37<02:55,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5139197111129761 Batch_id=202 Accuracy=30.33:  22%|██▏       | 203/938 [00:37<02:55,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7359285354614258 Batch_id=203 Accuracy=30.58:  22%|██▏       | 203/938 [00:37<02:55,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7359285354614258 Batch_id=203 Accuracy=30.58:  22%|██▏       | 204/938 [00:37<02:56,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5092164278030396 Batch_id=204 Accuracy=30.84:  22%|██▏       | 204/938 [00:37<02:56,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5092164278030396 Batch_id=204 Accuracy=30.84:  22%|██▏       | 205/938 [00:37<02:49,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7094402313232422 Batch_id=205 Accuracy=31.08:  22%|██▏       | 205/938 [00:37<02:49,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7094402313232422 Batch_id=205 Accuracy=31.08:  22%|██▏       | 206/938 [00:37<02:35,  4.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4331042170524597 Batch_id=206 Accuracy=31.36:  22%|██▏       | 206/938 [00:38<02:35,  4.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4331042170524597 Batch_id=206 Accuracy=31.36:  22%|██▏       | 207/938 [00:38<02:26,  5.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7042755484580994 Batch_id=207 Accuracy=31.56:  22%|██▏       | 207/938 [00:38<02:26,  5.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7042755484580994 Batch_id=207 Accuracy=31.56:  22%|██▏       | 208/938 [00:38<02:18,  5.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5440235137939453 Batch_id=208 Accuracy=31.81:  22%|██▏       | 208/938 [00:38<02:18,  5.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5440235137939453 Batch_id=208 Accuracy=31.81:  22%|██▏       | 209/938 [00:38<02:16,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5027281045913696 Batch_id=209 Accuracy=32.05:  22%|██▏       | 209/938 [00:38<02:16,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5027281045913696 Batch_id=209 Accuracy=32.05:  22%|██▏       | 210/938 [00:38<02:13,  5.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3642510175704956 Batch_id=210 Accuracy=32.34:  22%|██▏       | 210/938 [00:38<02:13,  5.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3642510175704956 Batch_id=210 Accuracy=32.34:  22%|██▏       | 211/938 [00:38<02:07,  5.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.45309844613075256 Batch_id=211 Accuracy=32.58:  22%|██▏       | 211/938 [00:38<02:07,  5.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.45309844613075256 Batch_id=211 Accuracy=32.58:  23%|██▎       | 212/938 [00:38<02:18,  5.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5943419933319092 Batch_id=212 Accuracy=32.81:  23%|██▎       | 212/938 [00:39<02:18,  5.25it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5943419933319092 Batch_id=212 Accuracy=32.81:  23%|██▎       | 213/938 [00:39<02:12,  5.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6162968277931213 Batch_id=213 Accuracy=33.04:  23%|██▎       | 213/938 [00:39<02:12,  5.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6162968277931213 Batch_id=213 Accuracy=33.04:  23%|██▎       | 214/938 [00:39<02:11,  5.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.37673404812812805 Batch_id=214 Accuracy=33.30:  23%|██▎       | 214/938 [00:39<02:11,  5.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.37673404812812805 Batch_id=214 Accuracy=33.30:  23%|██▎       | 215/938 [00:39<02:12,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.31339600682258606 Batch_id=215 Accuracy=33.56:  23%|██▎       | 215/938 [00:39<02:12,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.31339600682258606 Batch_id=215 Accuracy=33.56:  23%|██▎       | 216/938 [00:39<02:13,  5.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.34051623940467834 Batch_id=216 Accuracy=33.83:  23%|██▎       | 216/938 [00:39<02:13,  5.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.34051623940467834 Batch_id=216 Accuracy=33.83:  23%|██▎       | 217/938 [00:39<02:09,  5.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6237757802009583 Batch_id=217 Accuracy=34.05:  23%|██▎       | 217/938 [00:40<02:09,  5.58it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6237757802009583 Batch_id=217 Accuracy=34.05:  23%|██▎       | 218/938 [00:40<02:12,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3487497866153717 Batch_id=218 Accuracy=34.30:  23%|██▎       | 218/938 [00:40<02:12,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3487497866153717 Batch_id=218 Accuracy=34.30:  23%|██▎       | 219/938 [00:40<02:11,  5.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.45471885800361633 Batch_id=219 Accuracy=34.54:  23%|██▎       | 219/938 [00:40<02:11,  5.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.45471885800361633 Batch_id=219 Accuracy=34.54:  23%|██▎       | 220/938 [00:40<02:20,  5.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4760732054710388 Batch_id=220 Accuracy=34.76:  23%|██▎       | 220/938 [00:40<02:20,  5.10it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4760732054710388 Batch_id=220 Accuracy=34.76:  24%|██▎       | 221/938 [00:40<02:33,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6367453932762146 Batch_id=221 Accuracy=35.00:  24%|██▎       | 221/938 [00:40<02:33,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6367453932762146 Batch_id=221 Accuracy=35.00:  24%|██▎       | 222/938 [00:40<02:40,  4.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3079501688480377 Batch_id=222 Accuracy=35.26:  24%|██▎       | 222/938 [00:41<02:40,  4.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3079501688480377 Batch_id=222 Accuracy=35.26:  24%|██▍       | 223/938 [00:41<02:45,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.9208188652992249 Batch_id=223 Accuracy=35.46:  24%|██▍       | 223/938 [00:41<02:45,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.9208188652992249 Batch_id=223 Accuracy=35.46:  24%|██▍       | 224/938 [00:41<02:51,  4.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3204689919948578 Batch_id=224 Accuracy=35.70:  24%|██▍       | 224/938 [00:41<02:51,  4.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3204689919948578 Batch_id=224 Accuracy=35.70:  24%|██▍       | 225/938 [00:41<02:57,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3921588063240051 Batch_id=225 Accuracy=35.92:  24%|██▍       | 225/938 [00:41<02:57,  4.02it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.3921588063240051 Batch_id=225 Accuracy=35.92:  24%|██▍       | 226/938 [00:41<02:55,  4.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4644676446914673 Batch_id=226 Accuracy=36.14:  24%|██▍       | 226/938 [00:42<02:55,  4.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4644676446914673 Batch_id=226 Accuracy=36.14:  24%|██▍       | 227/938 [00:42<02:56,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6875401139259338 Batch_id=227 Accuracy=36.35:  24%|██▍       | 227/938 [00:42<02:56,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6875401139259338 Batch_id=227 Accuracy=36.35:  24%|██▍       | 228/938 [00:42<02:52,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6044303178787231 Batch_id=228 Accuracy=36.56:  24%|██▍       | 228/938 [00:42<02:52,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6044303178787231 Batch_id=228 Accuracy=36.56:  24%|██▍       | 229/938 [00:42<02:50,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3505236506462097 Batch_id=229 Accuracy=36.78:  24%|██▍       | 229/938 [00:42<02:50,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3505236506462097 Batch_id=229 Accuracy=36.78:  25%|██▍       | 230/938 [00:42<02:34,  4.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.47215786576271057 Batch_id=230 Accuracy=36.99:  25%|██▍       | 230/938 [00:43<02:34,  4.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.47215786576271057 Batch_id=230 Accuracy=36.99:  25%|██▍       | 231/938 [00:43<02:26,  4.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.43060562014579773 Batch_id=231 Accuracy=37.21:  25%|██▍       | 231/938 [00:43<02:26,  4.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.43060562014579773 Batch_id=231 Accuracy=37.21:  25%|██▍       | 232/938 [00:43<02:14,  5.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4830097556114197 Batch_id=232 Accuracy=37.40:  25%|██▍       | 232/938 [00:43<02:14,  5.25it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4830097556114197 Batch_id=232 Accuracy=37.40:  25%|██▍       | 233/938 [00:43<02:11,  5.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4834735095500946 Batch_id=233 Accuracy=37.59:  25%|██▍       | 233/938 [00:43<02:11,  5.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4834735095500946 Batch_id=233 Accuracy=37.59:  25%|██▍       | 234/938 [00:43<02:08,  5.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3556593954563141 Batch_id=234 Accuracy=37.80:  25%|██▍       | 234/938 [00:43<02:08,  5.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3556593954563141 Batch_id=234 Accuracy=37.80:  25%|██▌       | 235/938 [00:43<02:04,  5.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5715949535369873 Batch_id=235 Accuracy=37.97:  25%|██▌       | 235/938 [00:43<02:04,  5.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.5715949535369873 Batch_id=235 Accuracy=37.97:  25%|██▌       | 236/938 [00:43<02:10,  5.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2916751205921173 Batch_id=236 Accuracy=38.21:  25%|██▌       | 236/938 [00:44<02:10,  5.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2916751205921173 Batch_id=236 Accuracy=38.21:  25%|██▌       | 237/938 [00:44<02:03,  5.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3700152039527893 Batch_id=237 Accuracy=38.41:  25%|██▌       | 237/938 [00:44<02:03,  5.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3700152039527893 Batch_id=237 Accuracy=38.41:  25%|██▌       | 238/938 [00:44<02:16,  5.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4351610243320465 Batch_id=238 Accuracy=38.60:  25%|██▌       | 238/938 [00:44<02:16,  5.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4351610243320465 Batch_id=238 Accuracy=38.60:  25%|██▌       | 239/938 [00:44<02:20,  4.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.42829659581184387 Batch_id=239 Accuracy=38.80:  25%|██▌       | 239/938 [00:44<02:20,  4.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.42829659581184387 Batch_id=239 Accuracy=38.80:  26%|██▌       | 240/938 [00:44<02:25,  4.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7007972598075867 Batch_id=240 Accuracy=38.98:  26%|██▌       | 240/938 [00:44<02:25,  4.79it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.7007972598075867 Batch_id=240 Accuracy=38.98:  26%|██▌       | 241/938 [00:44<02:32,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.39718887209892273 Batch_id=241 Accuracy=39.19:  26%|██▌       | 241/938 [00:45<02:32,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.39718887209892273 Batch_id=241 Accuracy=39.19:  26%|██▌       | 242/938 [00:45<02:36,  4.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2771323323249817 Batch_id=242 Accuracy=39.41:  26%|██▌       | 242/938 [00:45<02:36,  4.43it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2771323323249817 Batch_id=242 Accuracy=39.41:  26%|██▌       | 243/938 [00:45<02:45,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.38154226541519165 Batch_id=243 Accuracy=39.63:  26%|██▌       | 243/938 [00:45<02:45,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.38154226541519165 Batch_id=243 Accuracy=39.63:  26%|██▌       | 244/938 [00:45<02:42,  4.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.42881661653518677 Batch_id=244 Accuracy=39.83:  26%|██▌       | 244/938 [00:45<02:42,  4.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.42881661653518677 Batch_id=244 Accuracy=39.83:  26%|██▌       | 245/938 [00:45<02:46,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.35666096210479736 Batch_id=245 Accuracy=40.02:  26%|██▌       | 245/938 [00:46<02:46,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.35666096210479736 Batch_id=245 Accuracy=40.02:  26%|██▌       | 246/938 [00:46<02:52,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3349204659461975 Batch_id=246 Accuracy=40.21:  26%|██▌       | 246/938 [00:46<02:52,  4.01it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3349204659461975 Batch_id=246 Accuracy=40.21:  26%|██▋       | 247/938 [00:46<03:45,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3391481637954712 Batch_id=247 Accuracy=40.40:  26%|██▋       | 247/938 [00:47<03:45,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3391481637954712 Batch_id=247 Accuracy=40.40:  26%|██▋       | 248/938 [00:47<06:10,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3506459593772888 Batch_id=248 Accuracy=40.58:  26%|██▋       | 248/938 [00:49<06:10,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3506459593772888 Batch_id=248 Accuracy=40.58:  27%|██▋       | 249/938 [00:49<10:52,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.472546249628067 Batch_id=249 Accuracy=40.77:  27%|██▋       | 249/938 [00:57<10:52,  1.06it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.472546249628067 Batch_id=249 Accuracy=40.77:  27%|██▋       | 250/938 [00:57<33:21,  2.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4010770618915558 Batch_id=250 Accuracy=40.94:  27%|██▋       | 250/938 [01:01<33:21,  2.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4010770618915558 Batch_id=250 Accuracy=40.94:  27%|██▋       | 251/938 [01:01<37:29,  3.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4016740620136261 Batch_id=251 Accuracy=41.11:  27%|██▋       | 251/938 [03:02<37:29,  3.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4016740620136261 Batch_id=251 Accuracy=41.11:  27%|██▋       | 252/938 [03:02<7:21:38, 38.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.22070184350013733 Batch_id=252 Accuracy=41.30:  27%|██▋       | 252/938 [03:02<7:21:38, 38.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.22070184350013733 Batch_id=252 Accuracy=41.30:  27%|██▋       | 253/938 [03:02<5:09:27, 27.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.30838438868522644 Batch_id=253 Accuracy=41.49:  27%|██▋       | 253/938 [03:02<5:09:27, 27.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.30838438868522644 Batch_id=253 Accuracy=41.49:  27%|██▋       | 254/938 [03:02<3:37:13, 19.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3153691291809082 Batch_id=254 Accuracy=41.68:  27%|██▋       | 254/938 [03:03<3:37:13, 19.06s/it] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3153691291809082 Batch_id=254 Accuracy=41.68:  27%|██▋       | 255/938 [03:03<2:32:45, 13.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.47210344672203064 Batch_id=255 Accuracy=41.86:  27%|██▋       | 255/938 [03:03<2:32:45, 13.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.47210344672203064 Batch_id=255 Accuracy=41.86:  27%|██▋       | 256/938 [03:03<1:47:39,  9.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3775205612182617 Batch_id=256 Accuracy=42.05:  27%|██▋       | 256/938 [03:03<1:47:39,  9.47s/it] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3775205612182617 Batch_id=256 Accuracy=42.05:  27%|██▋       | 257/938 [03:03<1:16:29,  6.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.36606183648109436 Batch_id=257 Accuracy=42.24:  27%|██▋       | 257/938 [03:04<1:16:29,  6.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.36606183648109436 Batch_id=257 Accuracy=42.24:  28%|██▊       | 258/938 [03:04<54:26,  4.80s/it]  \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.22148747742176056 Batch_id=258 Accuracy=42.43:  28%|██▊       | 258/938 [03:04<54:26,  4.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.22148747742176056 Batch_id=258 Accuracy=42.43:  28%|██▊       | 259/938 [03:04<38:54,  3.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6493683457374573 Batch_id=259 Accuracy=42.60:  28%|██▊       | 259/938 [03:04<38:54,  3.44s/it] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.6493683457374573 Batch_id=259 Accuracy=42.60:  28%|██▊       | 260/938 [03:04<27:45,  2.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.35555627942085266 Batch_id=260 Accuracy=42.77:  28%|██▊       | 260/938 [03:04<27:45,  2.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.35555627942085266 Batch_id=260 Accuracy=42.77:  28%|██▊       | 261/938 [03:04<20:04,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3151039481163025 Batch_id=261 Accuracy=42.96:  28%|██▊       | 261/938 [03:04<20:04,  1.78s/it] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3151039481163025 Batch_id=261 Accuracy=42.96:  28%|██▊       | 262/938 [03:04<14:41,  1.30s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.35852330923080444 Batch_id=262 Accuracy=43.14:  28%|██▊       | 262/938 [03:05<14:41,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.35852330923080444 Batch_id=262 Accuracy=43.14:  28%|██▊       | 263/938 [03:05<11:02,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3660157024860382 Batch_id=263 Accuracy=43.32:  28%|██▊       | 263/938 [03:05<11:02,  1.02it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3660157024860382 Batch_id=263 Accuracy=43.32:  28%|██▊       | 264/938 [03:05<08:28,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.24980498850345612 Batch_id=264 Accuracy=43.50:  28%|██▊       | 264/938 [03:05<08:28,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.24980498850345612 Batch_id=264 Accuracy=43.50:  28%|██▊       | 265/938 [03:05<06:40,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3454190790653229 Batch_id=265 Accuracy=43.67:  28%|██▊       | 265/938 [03:05<06:40,  1.68it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3454190790653229 Batch_id=265 Accuracy=43.67:  28%|██▊       | 266/938 [03:05<05:14,  2.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2957078814506531 Batch_id=266 Accuracy=43.87:  28%|██▊       | 266/938 [03:05<05:14,  2.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2957078814506531 Batch_id=266 Accuracy=43.87:  28%|██▊       | 267/938 [03:05<04:22,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4027724862098694 Batch_id=267 Accuracy=44.02:  28%|██▊       | 267/938 [03:06<04:22,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4027724862098694 Batch_id=267 Accuracy=44.02:  29%|██▊       | 268/938 [03:06<03:47,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.27467960119247437 Batch_id=268 Accuracy=44.20:  29%|██▊       | 268/938 [03:06<03:47,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.27467960119247437 Batch_id=268 Accuracy=44.20:  29%|██▊       | 269/938 [03:06<04:06,  2.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3615882992744446 Batch_id=269 Accuracy=44.36:  29%|██▊       | 269/938 [03:11<04:06,  2.71it/s] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3615882992744446 Batch_id=269 Accuracy=44.36:  29%|██▉       | 270/938 [03:11<18:14,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3648408055305481 Batch_id=270 Accuracy=44.52:  29%|██▉       | 270/938 [03:16<18:14,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.3648408055305481 Batch_id=270 Accuracy=44.52:  29%|██▉       | 271/938 [03:16<30:14,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.36240577697753906 Batch_id=271 Accuracy=44.69:  29%|██▉       | 271/938 [03:22<30:14,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.36240577697753906 Batch_id=271 Accuracy=44.69:  29%|██▉       | 272/938 [03:22<41:07,  3.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4975765347480774 Batch_id=272 Accuracy=44.84:  29%|██▉       | 272/938 [03:23<41:07,  3.70s/it] \u001b[A\u001b[A\n",
      "\n",
      "Loss=0.4975765347480774 Batch_id=272 Accuracy=44.84:  29%|██▉       | 273/938 [03:23<32:52,  2.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2775193452835083 Batch_id=273 Accuracy=45.03:  29%|██▉       | 273/938 [03:26<32:52,  2.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2775193452835083 Batch_id=273 Accuracy=45.03:  29%|██▉       | 274/938 [03:26<30:49,  2.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2554579973220825 Batch_id=274 Accuracy=45.19:  29%|██▉       | 274/938 [08:27<30:49,  2.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loss=0.2554579973220825 Batch_id=274 Accuracy=45.19:  29%|██▉       | 275/938 [08:27<17:00:41, 92.37s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model =  Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
    "axs[0, 0].plot(train_losses)\n",
    "axs[0, 0].set_title(\"Training Loss\")\n",
    "axs[1, 0].plot(train_acc)\n",
    "axs[1, 0].set_title(\"Training Accuracy\")\n",
    "axs[0, 1].plot(test_losses)\n",
    "axs[0, 1].set_title(\"Test Loss\")\n",
    "axs[1, 1].plot(test_acc)\n",
    "axs[1, 1].set_title(\"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov3_pytorch",
   "language": "python",
   "name": "yolov3_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
